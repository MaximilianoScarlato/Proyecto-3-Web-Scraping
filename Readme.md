# Web Scraper Fusion

## ğŸ“Œ Ãndice
- [ğŸ“ Sobre el Proyecto](#sobre-el-proyecto)
- [âš¡ CaracterÃ­sticas principales](#caracterÃ­sticas-principales)
- [â›” Temas actuales](#temas-actuales)
- [ğŸ”§ Posibles mejoras](#posibles-mejoras)
- [ğŸ‘¨â€ğŸ’» TecnologÃ­as utilizadas](#tecnologÃ­as-utilizadas)
- [âš™ InstalaciÃ³n y uso](#instalaciÃ³n-y-uso)
- [ğŸ“‚ Estructura de la carpeta](#estructura-de-la-carpeta)
- [ğŸ§ª RealizaciÃ³n de pruebas](#realizaciÃ³n-de-pruebas)
- [ğŸŒŸ Estado del proyecto](#estado-del-proyecto)

## ğŸ“ Sobre el Proyecto
Web Scraper Fusion es un sistema backend desarrollado con Django y MySQL que permite realizar bÃºsquedas en PubMed, guardar artÃ­culos seleccionados y gestionar artÃ­culos duplicados. El objetivo principal es facilitar la recopilaciÃ³n y organizaciÃ³n de informaciÃ³n cientÃ­fica.

El sistema incluye las siguientes funcionalidades:
- BÃºsqueda de artÃ­culos en PubMed.
- GestiÃ³n de artÃ­culos seleccionados.
- Registro de artÃ­culos duplicados.
- Acceso directo a los enlaces de los artÃ­culos.

El proyecto sigue la metodologÃ­a Scrum y estÃ¡ organizado en GitHub. Incluye pruebas unitarias para garantizar la confiabilidad del cÃ³digo.

## âš¡ CaracterÃ­sticas principales
- âœ… BÃºsqueda de artÃ­culos en PubMed utilizando Selenium.
- âœ… GestiÃ³n de artÃ­culos seleccionados y duplicados.
- âœ… Columna "Seleccionar enlace" para acceder directamente a los artÃ­culos.
- âœ… Manejo de excepciones para artÃ­culos duplicados.
- âœ… Base de datos estructurada con las siguientes tablas:
  - `SelectedArticle`: ArtÃ­culos seleccionados.
  - `DuplicateArticle`: ArtÃ­culos duplicados.
- âœ… Uso de sesiones para almacenar temporalmente los resultados de bÃºsqueda.
- âœ… Interfaz de usuario con Bootstrap para una experiencia amigable.
- âœ… Scripts para creaciÃ³n de bases de datos y migraciÃ³n de datos antiguos.
- âœ… DocumentaciÃ³n del sistema y del cÃ³digo en GitHub.

## â›” Temas actuales
- âŒ El manejo de excepciones podrÃ­a ser mÃ¡s robusto.
- âŒ La funcionalidad de bÃºsqueda no incluye mÃ¡s de 1 URL.
- âŒ No se han implementado pruebas unitarias completas para todas las vistas.

## ğŸ”§ Posibles mejoras
- âœ… Implementar paginaciÃ³n en los resultados de bÃºsqueda.
- âœ… Mejorar la gestiÃ³n de excepciones para una retroalimentaciÃ³n mÃ¡s clara.
- âœ… Optimizar el rendimiento del scraping para bÃºsquedas mÃ¡s rÃ¡pidas.
- âœ… Agregar pruebas unitarias para todas las vistas y modelos.
- âœ… Permitir exportar los artÃ­culos seleccionados a formatos como CSV o Excel.

## ğŸ‘¨â€ğŸ’» TecnologÃ­as utilizadas
- **Backend**: Django (Python), Selenium.
- **Base de datos**: MySQL.
- **Interfaz**: HTML, CSS, Bootstrap.
- **Control de versiones**: Git / GitHub.
- **MetodologÃ­a**: Scrum.
- **Pruebas**: Pruebas unitarias y de integraciÃ³n con el framework de Django.
- **LibrerÃ­as Ãºtiles**: Scrapy, Requests, Selenium.
- **GestiÃ³n del proyecto**: GitHub.

## âš™ InstalaciÃ³n y uso

### ğŸ”½ Clonar el repositorio
```bash
git clone https://github.com/tu-usuario/webscraper-fusion.git
cd webscraper-fusion
```

### ğŸ“¦ Instalar dependencias
Crear y activar un entorno virtual:

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

**Linux/Mac:**
```bash
python -m venv venv
source venv/bin/activate
```

Instalar dependencias:
```bash
pip install -r requirements.txt
```

### âš™ Configurar la base de datos
AsegÃºrate de tener MySQL instalado y configurado. Luego, crea un archivo `.env` con las credenciales de tu base de datos:

```bash
touch .env
```

Contenido del archivo `.env`:
```env
mysql_username = 'tu_usuario'
mysql_password = 'tu_contraseÃ±a'
mysql_host = '127.0.0.1'
mysql_port = 3306
bbdd_name = 'webscraper_db'
```

### â†©ï¸ Realizar migraciones
```bash
python manage.py makemigrations
python manage.py migrate
```

### ğŸš€ Ejecutar el servidor
```bash
python manage.py runserver
```
Accede a la aplicaciÃ³n en: [http://127.0.0.1:8000/](http://127.0.0.1:8000/)

### ğŸš€ Ejecutar el comando de scraping
```bash
python manage.py scrape
```

## ğŸ“‚ Estructura de la carpeta

```
PROYECTO_3_WEB_SCRAPER
â”œâ”€â”€ logs
â”œâ”€â”€ scraper
â”‚   â”œâ”€â”€ __pycache__
â”‚   â”œâ”€â”€ management
â”‚   â”‚   â”œâ”€â”€ commands
â”‚   â”‚   â”‚   â”œâ”€â”€ __pycache__
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ scrape.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ migrations
â”‚   â”œâ”€â”€ services
â”‚   â”‚   â”œâ”€â”€ __pycache__
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ templates
â”‚   â”‚   â”œâ”€â”€ scraper
â”‚   â”‚   â”‚   â”œâ”€â”€ login.html
â”‚   â”‚   â”‚   â””â”€â”€ logout_confirm.html
â”‚   â”œâ”€â”€ tests
â”‚   â”‚   â”œâ”€â”€ __pycache__
â”‚   â”‚   â”œâ”€â”€ test_admin.py
â”‚   â”‚   â”œâ”€â”€ test_commands.py
â”‚   â”‚   â”œâ”€â”€ test_forms.py
â”‚   â”‚   â”œâ”€â”€ test_models.py
â”‚   â”‚   â”œâ”€â”€ test_services.py
â”‚   â”‚   â”œâ”€â”€ test_views.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ admin.py
â”‚   â”œâ”€â”€ apps.py
â”‚   â”œâ”€â”€ forms.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ urls.py
â”‚   â”œâ”€â”€ views.py
â”œâ”€â”€ static
â”œâ”€â”€ venv
â”œâ”€â”€ webscraper_project
â”‚   â”œâ”€â”€ __pycache__
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ asgi.py
â”‚   â”œâ”€â”€ settings.py
â”‚   â”œâ”€â”€ urls.py
â”‚   â”œâ”€â”€ wsgi.py
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ .gitignore
â”‚   â”œâ”€â”€ db.sqlite3
â”‚   â”œâ”€â”€ manage.py
â”‚   â”œâ”€â”€ Readme.md
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ run_tests.py
â”‚   â””â”€â”€ scraper.log
```

## ğŸ§ª RealizaciÃ³n de pruebas
Se realizan pruebas unitarias para `forms`, `views`, `admin`, `models`, `urls`, `scrapy` en `services` y `commands`. Los comandos individuales para ejecutar las pruebas son:

```bash
python manage.py test scraper.tests.test_admin
python manage.py test scraper.tests.test_forms
python manage.py test scraper.tests.test_models
python manage.py test scraper.tests.test_services
python manage.py test scraper.tests.test_views
python manage.py test scraper.tests.test_commands
```

AdemÃ¡s, se ha generado un comando para ejecutar todas las pruebas excepto `test_commands` (que requiere interacciÃ³n con el usuario):

```bash
python run_tests.py
```

Este comando ejecuta:
- `python manage.py test scraper.tests.test_admin`
- `python manage.py test scraper.tests.test_forms`
- `python manage.py test scraper.tests.test_models`
- `python manage.py test scraper.tests.test_services`
- `python manage.py test scraper.tests.test_views`

El comando `python manage.py test scraper.tests.test_commands` debe ejecutarse individualmente debido a que requiere interacciÃ³n con el usuario.

## ğŸŒŸ Estado del proyecto
El proyecto estÃ¡ en desarrollo. Se han implementado las funcionalidades principales, pero aÃºn hay Ã¡reas que requieren mejoras y optimizaciÃ³n.

Si este proyecto te resulta Ãºtil, Â¡marca el repositorio con una estrella en GitHub! â­
```

### **Cambios realizados:**
1. Se agregÃ³ la secciÃ³n **ğŸ§ª RealizaciÃ³n de pruebas** con los comandos individuales y el comando run_tests.py.
2. Se incluyÃ³ la nota sobre la ejecuciÃ³n individual de `test_commands` debido a la interacciÃ³n con el usuario.
3. Se configuraron correctamente los enlaces para que funcionen en GitHub.

Este archivo estÃ¡ listo para ser copiado y pegado en Visual Studio Code. ğŸ˜Š
